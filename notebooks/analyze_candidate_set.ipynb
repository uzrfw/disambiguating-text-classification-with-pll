{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analyze label distribution and quality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "from environment.env import getDataSourcePath, getNotebookDataSourcePath\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "categories = [\n",
    "    \"Culture and Art\",\n",
    "    \"Health\",\n",
    "    \"History\",\n",
    "    \"Science\",\n",
    "    \"People\",\n",
    "    \"Religion\",\n",
    "    \"Society\",\n",
    "    \"Technology\",\n",
    "    \"Geography and Places\"\n",
    "]\n",
    "\n",
    "db_path = getNotebookDataSourcePath()\n",
    "connection = sqlite3.connect(db_path)\n",
    "\n",
    "query_heuristic = 'SELECT sectionID, label FROM candidate_set_heuristics_validation'\n",
    "df_heuristic = pd.read_sql_query(query_heuristic, connection)\n",
    "\n",
    "query_llama_one = 'SELECT sectionID, label FROM candidate_set_llama2_1_validation'\n",
    "df_llama_1 = pd.read_sql_query(query_llama_one, connection)\n",
    "\n",
    "query_llama_two = 'SELECT sectionID, label FROM candidate_set_llama2_2_validation'\n",
    "df_llama_2 = pd.read_sql_query(query_llama_two, connection)\n",
    "\n",
    "query_llama_three = 'SELECT sectionID, label FROM candidate_set_llama2_3_validation'\n",
    "df_llama_3 = pd.read_sql_query(query_llama_three, connection)\n",
    "\n",
    "query_validation = 'SELECT sectionID, class FROM validation_data'\n",
    "df_validation = pd.read_sql_query(query_validation, connection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyze validation heuristic labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show important statistics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_counts = df_heuristic['label'].value_counts()\n",
    "barWidth = 0.25\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "label_counts.plot(kind='bar')\n",
    "plt.title('Frequency of labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Distribution')\n",
    "plt.show()\n",
    "\n",
    "labels_count_per_section = df_heuristic.groupby(['sectionID'])['label'].count()\n",
    "sections_per_label_count = labels_count_per_section.value_counts().sort_index()\n",
    "heuristic_average_label_count = labels_count_per_section.mean()\n",
    "plt.figure(figsize=(10,6))\n",
    "sections_per_label_count.plot(kind='bar')\n",
    "plt.title('Labels per section')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count per section')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check if there are sections without label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Analyze missing sectionIDs\n",
    "all_section_ids = set(df_validation['sectionID'])\n",
    "current_section_ids = set(df_heuristic['sectionID'])\n",
    "missing_section_ids = all_section_ids - current_section_ids\n",
    "\n",
    "print(len(missing_section_ids))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyze Llama labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_counts_1 = df_llama_1['label'].value_counts()\n",
    "label_counts_2 = df_llama_2['label'].value_counts()\n",
    "label_counts_3 = df_llama_3['label'].value_counts()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'One label': label_counts_1,\n",
    "    'Two labels': label_counts_2,\n",
    "    'Three labels': label_counts_3})\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "df.plot(kind='bar')\n",
    "\n",
    "plt.title('Frequency of labels')\n",
    "plt.ylabel('Distribution')\n",
    "plt.xlabel('Label')\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(categories)), labels=categories, rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyze candidate set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_section_ids = pd.merge(pd.DataFrame({'sectionID': df_heuristic['sectionID']}), pd.DataFrame({'sectionID': df_llama_2['sectionID']}), how='outer').drop_duplicates(subset='sectionID')\n",
    "df_mix = pd.merge(df_section_ids, df_llama_2, on='sectionID', how='left')\n",
    "df_mix = pd.merge(df_mix, df_heuristic, on='sectionID', how='left').fillna({'labels': '1,2,3,4,5,6,7,8,9'})\n",
    "\n",
    "label_counts = df_mix['label'].value_counts()\n",
    "plt.figure(figsize=(10,6))\n",
    "label_counts.plot(kind='bar')\n",
    "plt.title('Frequency of labels')\n",
    "plt.ylabel('Distribution')\n",
    "plt.show()\n",
    "\n",
    "labels_count_per_section = df_mix.groupby(['sectionID'])['label'].count()\n",
    "sections_per_label_count = labels_count_per_section.value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sections_per_label_count.plot(kind='bar')\n",
    "plt.title('Labels per section')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count per section')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check label quality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.category import convert_big_to_medium_category_index\n",
    "from evaluation.evaluator import Evaluator\n",
    "\n",
    "predictions_heuristic = []\n",
    "targets = []\n",
    "\n",
    "for (element, v_class) in zip(df_validation['sectionID'], df_validation['class']):\n",
    "    labels_array = df_heuristic[df_heuristic['sectionID'] == element]['label'].values\n",
    "    predictions_heuristic.append(labels_array)\n",
    "    targets.append([convert_big_to_medium_category_index(str(v_class - 1))])\n",
    "\n",
    "evaluator_heuristic = Evaluator(predictions_heuristic, targets)\n",
    "print(\"Evaluation score of heuristic labels:\")\n",
    "accuracy_heuristic = evaluator_heuristic.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_one = []\n",
    "predictions_two = []\n",
    "predictions_three = []\n",
    "predictions_hone = []\n",
    "\n",
    "targets = []\n",
    "\n",
    "for (element, v_class) in zip(df_validation['sectionID'], df_validation['class']):\n",
    "    predictions_one.append(df_llama_1[df_llama_1['sectionID'] == element]['label'].values)\n",
    "    predictions_two.append(df_llama_2[df_llama_2['sectionID'] == element]['label'].values)\n",
    "    predictions_three.append(df_llama_3[df_llama_3['sectionID'] == element]['label'].values)\n",
    "    predictions_hone.append(df_llama_1[df_llama_1['sectionID'] == element]['label'].values or df_heuristic[df_heuristic['sectionID'] == element]['label'].values)\n",
    "    targets.append([convert_big_to_medium_category_index(str(v_class - 1))])\n",
    "\n",
    "evaluator_hllama_1 = Evaluator(predictions_hone, targets)\n",
    "evaluator_llama_1 = Evaluator(predictions_one, targets)\n",
    "evaluator_llama_2 = Evaluator(predictions_two, targets)\n",
    "evaluator_llama_3 = Evaluator(predictions_three, targets)\n",
    "print(\"Evaluation score of llama labels:\")\n",
    "accuracy_hllama_1 = evaluator_hllama_1.evaluate()\n",
    "accuracy_llama_1 = evaluator_llama_1.evaluate()\n",
    "accuracy_llama_2 = evaluator_llama_2.evaluate()\n",
    "accuracy_llama_3 = evaluator_llama_3.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "predictions = []\n",
    "targets = []\n",
    "\n",
    "for (element, v_class) in zip(df_validation['sectionID'], df_validation['class']):\n",
    "    labels_array = numpy.concatenate([df_llama_2[df_llama_2['sectionID'] == element]['label'].values, df_heuristic[df_heuristic['sectionID'] == element]['label'].values])\n",
    "    predictions.append(labels_array)\n",
    "    targets.append([convert_big_to_medium_category_index(str(v_class - 1))])\n",
    "\n",
    "evaluator = Evaluator(predictions, targets)\n",
    "print(\"Evaluation score of labels:\")\n",
    "evaluator.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar([\"Heuristic\", \"Llama 1\", \"Llama 2\", \"Llama 3\"], [accuracy_heuristic, accuracy_llama_1, accuracy_llama_2, accuracy_llama_3], color=['blue', 'green', 'orange', 'red'])\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison of Models')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(\n",
    "    [\"Heuristics\", \"Llama 1\", \"Llama 2\", \"Llama 3\"],\n",
    "    [accuracy_heuristic / heuristic_average_label_count, accuracy_llama_1 / 1, accuracy_llama_2 / 2, accuracy_llama_3 / 3],\n",
    "    color=['blue', 'green', 'orange', 'red']\n",
    ")\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison of Models')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_counts = df_llama_1['label'].value_counts()\n",
    "barWidth = 0.25\n",
    "\n",
    "labels_count_per_section = df_llama_1.groupby(['sectionID'])['label'].count()\n",
    "sections_per_label_count = labels_count_per_section.value_counts().sort_index()\n",
    "heuristic_average_label_count = labels_count_per_section.mean()\n",
    "plt.figure(figsize=(10,6))\n",
    "sections_per_label_count.plot(kind='bar')\n",
    "plt.title('Labels per section')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count per section')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
